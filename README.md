# Machine Learning Workshop

## Introduction

Welcome to the Machine Learning Workshop! This workshop is designed to give you a solid foundation in machine learning concepts, models, and techniques, using Python and popular libraries like Scikit-Learn and TensorFlow. Whether you are a beginner or have some experience, this workshop will guide you through the fundamentals and advanced topics in machine learning.

This README provides an overview of the topics covered in this workshop, which are aligned with the engineering syllabus and reference the textbook "Hands-On Machine Learning with Scikit-Learn and TensorFlow" by Aurélien Géron.

## Table of Contents

1. [Module 1: The Machine Learning Landscape](#module-1-the-machine-learning-landscape)
   - What Is Machine Learning?
   - Types of Machine Learning
   - Main Challenges of Machine Learning
   - End-to-End Machine Learning Project
   - Bayesian Decision Theory
2. [Module 2: Classification and Training Models](#module-2-classification-and-training-models)
   - Classification: MNIST, Training a Binary Classifier
   - Performance Measures, Multiclass Classification
   - Training Models: Linear Regression, Gradient Descent
   - Regularized Linear Models: Ridge & Lasso Regression
3. [Module 3: Dimensionality Reduction and Support Vector Machines](#module-3-dimensionality-reduction-and-support-vector-machines)
   - Dimensionality Reduction: The Curse of Dimensionality
   - PCA, Linear Discriminant Analysis (LDA)
   - Support Vector Machines (SVM)
4. [Module 4: Decision Trees](#module-4-decision-trees)
   - Decision Trees: Univariate Trees
   - Pruning, Rule Extraction, Making Predictions
   - Estimating Class Probabilities, Computational Complexity
   - Gini Impurity, Regularization Hyperparameters
5. [Module 5: Ensemble Learning and Unsupervised Learning](#module-5-ensemble-learning-and-unsupervised-learning)
   - Ensemble Learning and Random Forests
   - Unsupervised Learning Techniques: Clustering

## [Module 1: The Machine Learning Landscape](./chapters/module1.md)

### 1.1 What Is Machine Learning?
- **Objective:** Understand what machine learning is and its importance in modern technology.
- **Topics:**
  - Definition of Machine Learning
  - Key Terminologies: Model, Algorithm, Feature
  - Real-world applications of Machine Learning

### 1.2 Types of Machine Learning
- **Objective:** Learn about the various types of machine learning and their applications.
- **Topics:**
  - Supervised Learning
  - Unsupervised Learning
  - Semi-supervised Learning
  - Reinforcement Learning

### 1.3 Main Challenges of Machine Learning
- **Objective:** Explore the common challenges faced in machine learning projects.
- **Topics:**
  - Overfitting vs. Underfitting
  - Bias-Variance Tradeoff
  - Data Quality and Quantity

### 1.4 End-to-End Machine Learning Project
- **Objective:** Work on a real-world dataset to build a complete machine learning pipeline.
- **Topics:**
  - Frame the Problem
  - Select the Performance Measure
  - Prepare the Data
  - Model Selection and Training
  - Testing and Validating the Model

### 1.5 Bayesian Decision Theory
- **Objective:** Introduction to Bayesian Decision Theory.
- **Topics:**
  - Basics of Probability Theory
  - Bayesian Classification

## [Module 2: Classification and Training Models](./chapters/module2.md)

### 2.1 Classification: MNIST, Training Binary Classifier
- **Objective:** Understand the basics of classification using the MNIST dataset.
- **Topics:**
  - Binary Classifiers
  - Decision Boundaries
  - Confusion Matrix

### 2.2 Performance Measures, Multiclass Classification
- **Objective:** Learn how to evaluate classification models.
- **Topics:**
  - Precision, Recall, F1 Score
  - ROC Curve
  - Multiclass vs. Multilabel Classification

### 2.3 Training Models: Linear Regression, Gradient Descent
- **Objective:** Dive into linear regression and optimization techniques.
- **Topics:**
  - Linear Regression Model
  - Gradient Descent Algorithm
  - Learning Rate and Convergence

### 2.4 Regularized Linear Models: Ridge & Lasso Regression
- **Objective:** Explore regularization techniques to improve model generalization.
- **Topics:**
  - Ridge Regression (L2 Regularization)
  - Lasso Regression (L1 Regularization)
  - Elastic Net

## [Module 3: Dimensionality Reduction and Support Vector Machines](./chapters/module3.md)

### 3.1 Dimensionality Reduction: The Curse of Dimensionality
- **Objective:** Learn about the challenges and techniques for reducing data dimensions.
- **Topics:**
  - The Curse of Dimensionality
  - Feature Selection vs. Feature Extraction

### 3.2 PCA, Linear Discriminant Analysis (LDA)
- **Objective:** Understand the principles of PCA and LDA for dimensionality reduction.
- **Topics:**
  - Principal Component Analysis (PCA)
  - Linear Discriminant Analysis (LDA)
  - Choosing the Number of Components

### 3.3 Support Vector Machines (SVM)
- **Objective:** Master Support Vector Machines for classification and regression tasks.
- **Topics:**
  - Linear SVM Classification
  - Nonlinear SVMs
  - Kernel Trick

## [Module 4: Decision Trees](./chapters/module4.md)

### 4.1 Decision Trees: Univariate Trees
- **Objective:** Explore decision trees for both classification and regression tasks.
- **Topics:**
  - How Decision Trees Work
  - Gini Impurity and Information Gain

### 4.2 Pruning, Rule Extraction, Making Predictions
- **Objective:** Learn how to optimize decision trees.
- **Topics:**
  - Pruning Techniques
  - Rule Extraction from Trees
  - Making Predictions with Trees

### 4.3 Estimating Class Probabilities, Computational Complexity, CART Algorithm
- **Objective:** Understand the probabilistic interpretation and computational aspects of trees.
- **Topics:**
  - Estimating Class Probabilities
  - Computational Complexity
  - CART Algorithm

### 4.4 Gini Impurity, Regularization Hyperparameters
- **Objective:** Learn about regularization techniques to avoid overfitting.
- **Topics:**
  - Gini Impurity vs. Entropy
  - Regularization Hyperparameters
  - Multivariate Trees

## [Module 5: Ensemble Learning and Unsupervised Learning](./chapters/module5.md)

### 5.1 Ensemble Learning and Random Forests
- **Objective:** Explore ensemble methods to boost model performance.
- **Topics:**
  - Voting Classifiers
  - Bagging and Pasting
  - Random Forests

### 5.2 Unsupervised Learning Techniques: Clustering
- **Objective:** Understand the fundamentals of unsupervised learning.
- **Topics:**
  - K-Means Clustering
  - Spectral Clustering
  - Hierarchical Clustering
